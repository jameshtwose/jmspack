<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>jmspack.ml_utils &#8212; jmspack 0.1.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/jmspack_logo.png"></span>
          jmspack</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html"><code class="docutils literal notranslate"><span class="pre">jmspack.frequentist_statistics</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-jmspack.internal_utils"><code class="docutils literal notranslate"><span class="pre">jmspack.internal_utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-jmspack.ml_utils"><code class="docutils literal notranslate"><span class="pre">jmspack.ml_utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-jmspack.NLTSA"><code class="docutils literal notranslate"><span class="pre">jmspack.NLTSA</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-jmspack.utils"><code class="docutils literal notranslate"><span class="pre">jmspack.utils</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../NLTSA.html">Using <code class="docutils literal notranslate"><span class="pre">NLTSA</span></code> functions from the <code class="docutils literal notranslate"><span class="pre">jmspack</span></code> package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml_utils.html">Using <code class="docutils literal notranslate"><span class="pre">ml_utils</span></code> functions from the <code class="docutils literal notranslate"><span class="pre">jmspack</span></code> package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../internal_utils.html">Using <code class="docutils literal notranslate"><span class="pre">internal_utils</span></code> functions from the <code class="docutils literal notranslate"><span class="pre">jmspack</span></code> package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../imputation_utils.html">Using <code class="docutils literal notranslate"><span class="pre">imputation_utils</span></code> functions from the <code class="docutils literal notranslate"><span class="pre">jmspack</span></code> package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frequentist_statistics.html">Using <code class="docutils literal notranslate"><span class="pre">frequentist_statistics</span></code> functions from the <code class="docutils literal notranslate"><span class="pre">jmspack</span></code> package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <h1>Source code for jmspack.ml_utils</h1><div class="highlight"><pre>
<span></span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Submodule ml_utils.py includes the following functions:</span>

<span class="sd">- plot_decision_boundary(): Generate a simple plot of the decision boundary of a classifier.</span>

<span class="sd">- plot_cv_indices(): Visualise the inputted cross validation method in chunks.</span>

<span class="sd">- plot_learning_curve(): Plot the learning curve of an estimator as samples increase to evaluate overfitting.</span>

<span class="sd">- dict_of_models: A dictionary of useful models.</span>

<span class="sd">- multi_roc_auc_plot(): A utility to plot the ROC curves of multiple classifiers (suggested to use in conjunction with the dict_of_models).</span>

<span class="sd">- optimize_model(): A utility to run gridsearch and Recursive Feature Elimination on a classifier to return a model with the best parameters.</span>

<span class="sd">- plot_confusion_matrix(): Visualise a confusion matrix.</span>

<span class="sd">- summary_performance_metrics_classification(): A utility to return a selection of regularly used classification performance metrics.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Patch</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">ClassifierMixin</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">QuadraticDiscriminantAnalysis</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">learning_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="kn">from</span> <span class="nn">jmspack.utils</span> <span class="kn">import</span> <span class="n">JmsColors</span>


<div class="viewcode-block" id="plot_decision_boundary"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.plot_decision_boundary">[docs]</a><span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">clf</span><span class="p">:</span> <span class="n">ClassifierMixin</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(),</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Decision Boundary Logistic Regression&quot;</span><span class="p">,</span>
    <span class="n">legend_title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Legend&quot;</span><span class="p">,</span>
    <span class="n">h</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">),</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate a simple plot of the decision boundary of a classifier.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Classifier vector, where n_samples is the number of samples and</span>
<span class="sd">        n_features is the number of features.</span>
<span class="sd">    y : array-like, shape (n_samples)</span>
<span class="sd">        Target relative to X for classification. Datatype should be integers.</span>
<span class="sd">    clf : scikit-learn algorithm</span>
<span class="sd">        An object that has the `predict` and `predict_proba` methods</span>
<span class="sd">    h : int (default: 0.05)</span>
<span class="sd">        Step size in the mesh</span>
<span class="sd">    title : string</span>
<span class="sd">        Title for the plot.</span>
<span class="sd">    legend_title : string</span>
<span class="sd">        Legend title for the plot.</span>
<span class="sd">    figsize: tuple (default: (11.7, 8.27))</span>
<span class="sd">        Width and height of the figure in inches</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    boundaries: Figure</span>
<span class="sd">        Properties of the figure can be changed later, e.g. use `boundaries.axes[0].set_ylim(0,100)` to change ylim</span>
<span class="sd">    ax: Axes</span>
<span class="sd">        The axes associated with the boundaries Figure.</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import seaborn as sns</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import SVC</span>
<span class="sd">    &gt;&gt;&gt; data = sns.load_dataset(&quot;iris&quot;)</span>
<span class="sd">    &gt;&gt;&gt; # convert the target from string to category to numeric as sklearn cannot handle strings as target</span>
<span class="sd">    &gt;&gt;&gt; y = data[&quot;species&quot;]</span>
<span class="sd">    &gt;&gt;&gt; X = data[[&quot;sepal_length&quot;, &quot;sepal_width&quot;]]</span>
<span class="sd">    &gt;&gt;&gt; clf = SVC(kernel=&quot;rbf&quot;, gamma=2, C=1, probability=True)</span>
<span class="sd">    &gt;&gt;&gt; _ = plot_decision_boundary(X=X, y=y, clf=clf, title = &#39;Decision Boundary&#39;, legend_title = &quot;Species&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X must contains only two features.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_integer_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_object_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_categorical_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;The target variable y can only have the following dtype: [int, object, category].&quot;</span>
        <span class="p">)</span>

    <span class="n">label_0</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">label_1</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">values</span>

    <span class="c1">#     full_col_list = list(sns.color_palette(&quot;husl&quot;, len(np.unique(y))))</span>
    <span class="n">full_col_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">())</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_col_list</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;More labels in the data then colors in the color list. Either reduce the number of labels or expend the color list&quot;</span>
        <span class="p">)</span>

    <span class="n">sub_col_list</span> <span class="o">=</span> <span class="n">full_col_list</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))]</span>
    <span class="n">cmap_bold</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">sub_col_list</span><span class="p">)</span>

    <span class="c1"># Try to include a mapping in a later release (+ show categorical labels in the legend)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Plot the decision boundary. For that, we will assign a color to each</span>
    <span class="c1"># point in the mesh [x_min, x_max]x[y_min, y_max].</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">Z_proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z_max</span> <span class="o">=</span> <span class="n">Z_proba</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Take the class with highest probability</span>
    <span class="n">Z_max</span> <span class="o">=</span> <span class="n">Z_max</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Put the result into a color plot</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="n">Z_max</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Plot also the training points</span>
    <span class="n">training</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">label_0</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">label_1</span><span class="p">)</span>

    <span class="c1"># Add legend colors</span>
    <span class="n">leg1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="o">*</span><span class="n">training</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span>
        <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">borderaxespad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
        <span class="n">handlelength</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">handletextpad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">legend_title</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Add legend sizes</span>
    <span class="n">l1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.4</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.6</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l3</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.8</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l4</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;0.4&quot;</span><span class="p">,</span> <span class="s2">&quot;0.6&quot;</span><span class="p">,</span> <span class="s2">&quot;0.8&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="p">[</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">,</span> <span class="n">l3</span><span class="p">,</span> <span class="n">l4</span><span class="p">],</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">borderaxespad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">handlelength</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">handletextpad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Probabilities&quot;</span><span class="p">,</span>
        <span class="n">scatterpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">ax</span></div>


<div class="viewcode-block" id="plot_cv_indices"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.plot_cv_indices">[docs]</a><span class="k">def</span> <span class="nf">plot_cv_indices</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Create an example plot for indices of a cross-validation object.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tmp: </span>
<span class="sd">        TODO</span>
<span class="sd"> </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    TODO</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; #TODO</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># set plotting options</span>
    <span class="n">cmap_data</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Paired</span>
    <span class="n">cmap_cv</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

    <span class="c1"># Generate the training/testing visualizations for each CV split</span>
    <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">tt</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">group</span><span class="p">)):</span>
        <span class="c1"># Fill in indices with the training/test groups</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="n">indices</span><span class="p">[</span><span class="n">tt</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">indices</span><span class="p">[</span><span class="n">tr</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Visualize the results</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)),</span>
            <span class="p">[</span><span class="n">ii</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span>
            <span class="n">c</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;_&quot;</span><span class="p">,</span>
            <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_cv</span><span class="p">,</span>
            <span class="n">vmin</span><span class="o">=-</span><span class="mf">0.2</span><span class="p">,</span>
            <span class="n">vmax</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Plot the data classes and groups at the end</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="p">[</span><span class="n">ii</span> <span class="o">+</span> <span class="mf">1.5</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_data</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span> <span class="p">[</span><span class="n">ii</span> <span class="o">+</span> <span class="mf">2.5</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">group</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_data</span>
    <span class="p">)</span>

    <span class="c1"># Formatting</span>
    <span class="n">yticklabels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_splits</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">,</span> <span class="s2">&quot;group&quot;</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">yticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="n">yticklabels</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Sample index&quot;</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CV iteration&quot;</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="n">n_splits</span> <span class="o">+</span> <span class="mf">2.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">],</span>
        <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)],</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="p">[</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">cmap_cv</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)),</span> <span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">cmap_cv</span><span class="p">(</span><span class="mf">0.02</span><span class="p">))],</span>
        <span class="p">[</span><span class="s2">&quot;Testing set&quot;</span><span class="p">,</span> <span class="s2">&quot;Training set&quot;</span><span class="p">],</span>
        <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.02</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="c1"># Make the legend fit</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span></div>


<div class="viewcode-block" id="plot_learning_curve"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.plot_learning_curve">[docs]</a><span class="k">def</span> <span class="nf">plot_learning_curve</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">estimator</span><span class="p">:</span> <span class="n">BaseEstimator</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(),</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Learning Curve Logistic Regression&quot;</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cross_color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">JmsColors</span><span class="o">.</span><span class="n">PURPLE</span><span class="p">,</span>
    <span class="n">test_color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">JmsColors</span><span class="o">.</span><span class="n">YELLOW</span><span class="p">,</span>
    <span class="n">scoring</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
    <span class="n">ylim</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cv</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">train_sizes</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate a simple plot of the test and training learning curve.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : object type that implements the &quot;fit&quot; and &quot;predict&quot; methods</span>
<span class="sd">        An object of that type which is cloned for each validation.</span>
<span class="sd">    title : string</span>
<span class="sd">        Title for the chart.</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Training vector, where n_samples is the number of samples and</span>
<span class="sd">        n_features is the number of features.</span>
<span class="sd">    y : array-like, shape (n_samples) or (n_samples, n_features), optional</span>
<span class="sd">        Target relative to X for classification or regression;</span>
<span class="sd">        None for unsupervised learning.</span>
<span class="sd">    cross_color : string</span>
<span class="sd">        Signifies the color of the cross validation in the plot</span>
<span class="sd">    test_color : string</span>
<span class="sd">        Signifies the color of the test set in the plot</span>
<span class="sd">    scoring : string</span>
<span class="sd">        Signifies a scoring to evaluate the cross validation</span>
<span class="sd">    ylim : tuple, shape (ymin, ymax), optional</span>
<span class="sd">        Defines minimum and maximum yvalues plotted.</span>
<span class="sd">    cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">          - None, to use the default 3-fold cross-validation,</span>
<span class="sd">          - integer, to specify the number of folds.</span>
<span class="sd">          - :term:`CV splitter`,</span>
<span class="sd">          - An iterable yielding (train, test) splits as arrays of indices.</span>
<span class="sd">        For integer/None inputs, if ``y`` is binary or multiclass,</span>
<span class="sd">        :param groups:</span>
<span class="sd">        :class:`StratifiedKFold` used. If the estimator is not a classifier</span>
<span class="sd">        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.</span>
<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validators that can be used here.</span>
<span class="sd">    n_jobs : int or None, optional (default=None)</span>
<span class="sd">        Number of jobs to run in parallel.</span>
<span class="sd">        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">        for more details.</span>
<span class="sd">    train_sizes : array-like, shape (n_ticks,), dtype float or int</span>
<span class="sd">        Relative or absolute numbers of training examples that will be used to</span>
<span class="sd">        generate the learning curve. If the dtype is float, it is regarded as a</span>
<span class="sd">        fraction of the maximum size of the training set (that is determined</span>
<span class="sd">        by the selected validation method), i.e. it has to be within (0, 1].</span>
<span class="sd">        Otherwise it is interpreted as absolute sizes of the training sets.</span>
<span class="sd">        Note that for classification the number of samples usually have to</span>
<span class="sd">        be big enough to contain at least one sample from each class.</span>
<span class="sd">        (default: np.linspace(0.1, 1.0, 5))</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">*</span><span class="n">ylim</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Training examples&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">train_sizes</span><span class="p">,</span>
        <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
        <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">test_color</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">train_sizes</span><span class="p">,</span>
        <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
        <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">cross_color</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">test_color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training score&quot;</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">train_sizes</span><span class="p">,</span>
        <span class="n">test_scores_mean</span><span class="p">,</span>
        <span class="s2">&quot;o-&quot;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">cross_color</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Cross-validation score&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span></div>


<span class="c1"># create a dictionary of models</span>
<span class="n">dict_of_models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Gradient Boosting&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">GradientBoostingClassifier</span><span class="p">(),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;K_Neighbors Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;SVM Classifier (linear)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;SVM Classifier (Radial Basis Function; RBF)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Gaussian Process Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">GaussianProcessClassifier</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">RBF</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Decision Tree (depth=5)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Random Forest Classifier(depth=5)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Multilayer Perceptron (MLP) Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;AdaBoost Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">AdaBoostClassifier</span><span class="p">(),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Naive Bayes (Gaussian) Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">GaussianNB</span><span class="p">(),</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Quadratic Discriminant Analysis Classifier&quot;</span><span class="p">,</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">QuadraticDiscriminantAnalysis</span><span class="p">(),</span>
    <span class="p">},</span>
<span class="p">]</span>


<div class="viewcode-block" id="multi_roc_auc_plot"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.multi_roc_auc_plot">[docs]</a><span class="k">def</span> <span class="nf">multi_roc_auc_plot</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">models</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="n">dict_of_models</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
<span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;tmp</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tmp: </span>
<span class="sd">        TODO</span>
<span class="sd"> </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    TODO</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; #TODO</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># scale the data and create training and test sets of the data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="c1"># Below for loop iterates through your models list</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>  <span class="c1"># select the model</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># train the model</span>
        <span class="c1"># Compute False postive rate, and True positive rate</span>
        <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span>
            <span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># Calculate Area under the curve to display on the plot</span>
        <span class="n">auc_score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span>
            <span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;macro&quot;</span>
        <span class="p">)</span>
        <span class="c1"># Now, plot the computed values</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> ROC (area = </span><span class="si">%0.2f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">],</span> <span class="n">auc_score</span><span class="p">))</span>
    <span class="c1"># Custom settings for the plot</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;1-Specificity (False Positive Rate)&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Sensitivity (True Positive Rate)&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Receiver Operating Characteristics&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
    <span class="c1"># plt.show()  # Display</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span></div>


<div class="viewcode-block" id="optimize_model"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.optimize_model">[docs]</a><span class="k">def</span> <span class="nf">optimize_model</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">estimator</span><span class="p">:</span> <span class="n">BaseEstimator</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">RandomForestClassifier</span><span class="p">(),</span>
    <span class="n">grid_params_dict</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
        <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
        <span class="s2">&quot;max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;log2&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;sqrt&quot;</span><span class="p">],</span>
        <span class="s2">&quot;criterion&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gini&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">gridsearch_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;scoring&quot;</span><span class="p">:</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">},</span>
    <span class="n">rfe_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;n_features_to_select&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;tmp</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tmp: </span>
<span class="sd">        TODO</span>
<span class="sd"> </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    TODO</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; #TODO</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Perform a 75% training and 25% test data split</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="c1"># stratify=y,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Instantiate grid_dt</span>
    <span class="n">grid_dt</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
        <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">grid_params_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">gridsearch_kwargs</span>
    <span class="p">)</span>

    <span class="c1"># Optimize hyperparameter</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">grid_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Extract the best estimator</span>
    <span class="n">optimized_estimator</span> <span class="o">=</span> <span class="n">grid_dt</span><span class="o">.</span><span class="n">best_estimator_</span>

    <span class="c1"># Create the RFE with a optimized random forest</span>
    <span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">optimized_estimator</span><span class="p">,</span> <span class="o">**</span><span class="n">rfe_kwargs</span><span class="p">)</span>

    <span class="c1"># Fit the eliminator to the data</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># create dataframe with features ranking (high = dropped early on)</span>
    <span class="n">feature_ranking</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rfe</span><span class="o">.</span><span class="n">ranking_</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">feature_ranking</span> <span class="o">=</span> <span class="n">feature_ranking</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

    <span class="c1"># create dataframe with feature selected</span>
    <span class="n">feature_selected</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

    <span class="c1"># create dataframe with importances per feature</span>
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
        <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">optimized_estimator</span><span class="o">.</span><span class="n">feature_importances_</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
    <span class="p">)</span>

    <span class="c1"># Calculates the test set accuracy</span>
    <span class="c1"># acc = metrics.accuracy_score(y_test, rfe.predict(X_test))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">- Sizes :&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- X shape = </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- y shape = </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- X_train shape = </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- X_test shape = </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- y_train shape = </span><span class="si">{</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- y_test shape = </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">- Model info :&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Optimal Parameters = </span><span class="si">{</span><span class="n">optimized_estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Selected feature list = </span><span class="si">{</span><span class="n">feature_selected</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># print(&quot;- Accuracy score on test set = {0:.1%}&quot;.format(acc))</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">optimized_estimator</span><span class="p">,</span>
        <span class="n">feature_ranking</span><span class="p">,</span>
        <span class="n">feature_selected</span><span class="p">,</span>
        <span class="n">feature_importance</span><span class="p">,</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">optimized_estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;optimal_parameters&quot;</span><span class="p">]),</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="plot_confusion_matrix"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.plot_confusion_matrix">[docs]</a><span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span>
    <span class="n">cf</span><span class="p">,</span>
    <span class="n">group_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">categories</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">count</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">percent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">cbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">xyticks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">xyplotlabels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">sum_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cf:            </span>
<span class="sd">        confusion matrix to be passed in</span>
<span class="sd">    group_names:</span>
<span class="sd">        List of strings that represent the labels row by row to be shown in each square.</span>
<span class="sd">    categories:</span>
<span class="sd">        List of strings containing the categories to be displayed on the x,y axis. Default is &#39;auto&#39;</span>
<span class="sd">    count:</span>
<span class="sd">        If True, show the raw number in the confusion matrix. Default is True.</span>
<span class="sd">    normalize:</span>
<span class="sd">        If True, show the proportions for each category. Default is True.</span>
<span class="sd">    cbar:</span>
<span class="sd">        If True, show the color bar. The cbar values are based off the values in the confusion matrix. Default is True.</span>
<span class="sd">    xyticks:</span>
<span class="sd">        If True, show x and y ticks. Default is True.</span>
<span class="sd">    xyplotlabels:</span>
<span class="sd">        If True, show &#39;True Label&#39; and &#39;Predicted Label&#39; on the figure. Default is True.</span>
<span class="sd">    sum_stats:</span>
<span class="sd">        If True, display summary statistics below the figure. Default is True.</span>
<span class="sd">    figsize:</span>
<span class="sd">        Tuple representing the figure size. Default will be the matplotlib rcParams value.</span>
<span class="sd">    cmap:</span>
<span class="sd">        Colormap of the values displayed from matplotlib.pyplot.cm. Default is &#39;Blues&#39;</span>
<span class="sd">        See http://matplotlib.org/examples/color/colormaps_reference.html</span>
<span class="sd">    title:</span>
<span class="sd">        Title for the heatmap. Default is None.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

    <span class="c1"># CODE TO GENERATE TEXT INSIDE EACH SQUARE</span>
    <span class="n">blanks</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cf</span><span class="o">.</span><span class="n">size</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">group_names</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">group_names</span><span class="p">)</span> <span class="o">==</span> <span class="n">cf</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="n">group_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">group_names</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">group_labels</span> <span class="o">=</span> <span class="n">blanks</span>

    <span class="k">if</span> <span class="n">count</span><span class="p">:</span>
        <span class="n">group_counts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{0:0.0f}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">cf</span><span class="o">.</span><span class="n">flatten</span><span class="p">()]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">group_counts</span> <span class="o">=</span> <span class="n">blanks</span>

    <span class="k">if</span> <span class="n">percent</span><span class="p">:</span>
        <span class="n">group_percentages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;</span><span class="si">{0:.2%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">cf</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cf</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">group_percentages</span> <span class="o">=</span> <span class="n">blanks</span>

    <span class="n">box_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">v1</span><span class="si">}{</span><span class="n">v2</span><span class="si">}{</span><span class="n">v3</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v3</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">group_labels</span><span class="p">,</span> <span class="n">group_counts</span><span class="p">,</span> <span class="n">group_percentages</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">box_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">box_labels</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cf</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># CODE TO GENERATE SUMMARY STATISTICS &amp; TEXT FOR SUMMARY STATS</span>
    <span class="k">if</span> <span class="n">sum_stats</span><span class="p">:</span>
        <span class="c1"># Accuracy is sum of diagonal divided by total observations</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">cf</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cf</span><span class="p">))</span>

        <span class="c1"># if it is a binary confusion matrix, show some more stats</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Metrics for Binary Confusion Matrices</span>
            <span class="n">precision</span> <span class="o">=</span> <span class="n">cf</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cf</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">recall</span> <span class="o">=</span> <span class="n">cf</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cf</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
            <span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
            <span class="n">stats_text</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Accuracy=</span><span class="si">{:0.3f}</span><span class="se">\n</span><span class="s2">Precision=</span><span class="si">{:0.3f}</span><span class="se">\n</span><span class="s2">Recall=</span><span class="si">{:0.3f}</span><span class="se">\n</span><span class="s2">F1 Score=</span><span class="si">{:0.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">stats_text</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Accuracy=</span><span class="si">{:0.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stats_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="k">if</span> <span class="n">xyticks</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
        <span class="c1"># Do not show categories if xyticks is False</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># MAKE THE HEATMAP VISUALIZATION</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span>
        <span class="n">cf</span><span class="p">,</span>
        <span class="n">annot</span><span class="o">=</span><span class="n">box_labels</span><span class="p">,</span>
        <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
        <span class="n">cbar</span><span class="o">=</span><span class="n">cbar</span><span class="p">,</span>
        <span class="n">xticklabels</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span>
        <span class="n">yticklabels</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">xyplotlabels</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True label&quot;</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted label&quot;</span> <span class="o">+</span> <span class="n">stats_text</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">stats_text</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span></div>


<span class="k">def</span> <span class="nf">_bootstrap_auc</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">use_probabilities</span><span class="p">,</span> <span class="n">bootstraps</span><span class="p">,</span> <span class="n">fold_size</span><span class="p">,</span> <span class="n">random_state</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Internal function to bootstrap auc.</span>
<span class="sd">    Originates from the AI in healthcare specialization of coursera. https://www.coursera.org/specializations/ai-healthcare</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model:</span>
<span class="sd">        The fitted sklearn model.</span>
<span class="sd">    X_test: pd.Series</span>
<span class="sd">        The predictors used to match to y_true.</span>
<span class="sd">    y_true: pd.Series</span>
<span class="sd">        The actual binary targets.</span>
<span class="sd">    classes: list(str)</span>
<span class="sd">        List with the name of the classes in string format.</span>
<span class="sd">    bootstraps: int</span>
<span class="sd">        The number of bootstraps.</span>
<span class="sd">    fold_size: int</span>
<span class="sd">        The number of folds.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">use_probabilities</span><span class="p">:</span>
        <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">y_pred_proba</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>

    <span class="n">statistics</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bootstraps</span><span class="p">)</span>

    <span class="n">df_pos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">df_neg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">prevalence</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_pos</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="c1"># get positive examples for stratified sampling</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bootstraps</span><span class="p">):</span>
        <span class="c1"># stratified sampling of positive and negative examples</span>
        <span class="n">pos_sample</span> <span class="o">=</span> <span class="n">df_pos</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fold_size</span> <span class="o">*</span> <span class="n">prevalence</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span>
        <span class="n">neg_sample</span> <span class="o">=</span> <span class="n">df_neg</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fold_size</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prevalence</span><span class="p">)),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">y_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pos_sample</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">neg_sample</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>
        <span class="n">pred_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pos_sample</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">neg_sample</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">use_probabilities</span><span class="p">:</span>
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_sample</span><span class="p">,</span> <span class="n">pred_sample</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_sample</span><span class="p">,</span> <span class="n">pred_sample</span><span class="p">)</span>

        <span class="n">statistics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">max_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">statistics</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
    <span class="n">min_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">statistics</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mean</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (95% CI </span><span class="si">{</span><span class="n">min_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">max_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="summary_performance_metrics_classification"><a class="viewcode-back" href="../../usage.html#jmspack.ml_utils.summary_performance_metrics_classification">[docs]</a><span class="k">def</span> <span class="nf">summary_performance_metrics_classification</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">bootstraps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">fold_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">69420</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Summary of different evaluation metrics specific to a single class classification learning problem.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: sklearn.model</span>
<span class="sd">        A fitted sklearn model with predict() and predict_proba() methods.</span>
<span class="sd">    X_test: pd.DataFrame</span>
<span class="sd">        A data frame used to run predict the target values (y_pred).</span>
<span class="sd">    y_true: pd.Series or np.arrays</span>
<span class="sd">        Binary true values.</span>
<span class="sd">    bootstraps: int</span>
<span class="sd">    fold_size: int</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>
<span class="sd">    </span>
<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function returns the following metrics:</span>
<span class="sd">        - true positive (TP): The model classifies the example as positive, and the actual label also positive.</span>
<span class="sd">        - false positive (FP): The model classifies the example as positive, but the actual label is negative.</span>
<span class="sd">        - true negative (TN): The model classifies the example as negative, and the actual label is also negative.</span>
<span class="sd">        - false negative (FN): The model classifies the example as negative, but the label is actually positive.</span>
<span class="sd">        - accuracy: The fractions of predictions the model got right.</span>
<span class="sd">        - prevalance: The proportion of positive examples. Where y=1.</span>
<span class="sd">        - sensitivity: The probability that our test outputs positive given that the case is actually positive.</span>
<span class="sd">        - specificity: The probability that the test outputs negative given that the case is actually negative.</span>
<span class="sd">        - positive predictive value: The proportion of positive predictions that are true positives.</span>
<span class="sd">        - negative predictive value: The proportion of negative predictions that are true negatives.</span>
<span class="sd">        - auc: A measure of goodness of fit.</span>
<span class="sd">        - bootstrapped auc: The bootstrap estimates the uncertainty by resampling the dataset with replacement.</span>
<span class="sd">        - F1: The harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import datasets</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; data = datasets.load_breast_cancer()</span>
<span class="sd">    &gt;&gt;&gt; df = pd.DataFrame(data.data, columns=data.feature_names)</span>
<span class="sd">    &gt;&gt;&gt; df[&#39;target&#39;] = data.target</span>
<span class="sd">    &gt;&gt;&gt; X = data.data</span>
<span class="sd">    &gt;&gt;&gt; y = data.target</span>
<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y)</span>
<span class="sd">    &gt;&gt;&gt; clf = KNeighborsClassifier(n_neighbors=6)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(X_train, y_train)</span>
<span class="sd">    &gt;&gt;&gt; y_pred = clf.predict(X_test)</span>
<span class="sd">    &gt;&gt;&gt; summary_performance_metrics_classification(y_true=y_test, y_pred=y_pred)</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># check if the fitted model has the &quot;predict_proba&quot; attribute</span>
    <span class="k">if</span> <span class="s2">&quot;predict_proba&quot;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="c1"># check that the fitted model has the &quot;probability&quot; attribute</span>
        <span class="k">if</span> <span class="s2">&quot;probability&quot;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="c1"># and that it is set to True (this can be the case for SVC)</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">probability</span><span class="p">:</span>
                <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="c1"># auc</span>
                <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span>
                    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>
                <span class="n">auc_score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The classifier </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> does have the &#39;predict_proba&#39; method, however it does not have&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; the &#39;probability&#39; parameter set to True, hence model evaluation metrics will be based on &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;binary predictions&quot;</span>
                <span class="p">)</span>
                <span class="n">auc_score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the model has &quot;predict_proba and no &quot;probability&quot; boolean so it 100% has &quot;predict_proba&quot;</span>
            <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># auc</span>
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">auc_score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># the model has no &quot;predict_proba&quot; attribute so probabilities are not used</span>
        <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The classifier </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> does not have the &#39;predict_proba&#39; method, hence &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;model evaluation metrics will be based on binary predictions&quot;</span>
        <span class="p">)</span>
        <span class="n">auc_score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># bootstrapped auc</span>
    <span class="n">bootstrap_auc_metric</span> <span class="o">=</span> <span class="n">_bootstrap_auc</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">use_probabilities</span><span class="o">=</span><span class="n">predict_proba_bool</span><span class="p">,</span>
        <span class="n">bootstraps</span><span class="o">=</span><span class="n">bootstraps</span><span class="p">,</span>
        <span class="n">fold_size</span><span class="o">=</span><span class="n">fold_size</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># TP, TN, FP, FN</span>
    <span class="n">confusion_matrix_metric</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># accuracy</span>
    <span class="n">accuracy_score_metric</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># balanced accuracy</span>
    <span class="n">balanced_accuracy_score_metric</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># prevalance</span>
    <span class="n">prevalence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># sensitivity</span>
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

    <span class="c1"># specificity</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>

    <span class="c1"># positive predictive value</span>
    <span class="n">PPV</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>

    <span class="c1"># negative predictive value</span>
    <span class="n">NPV</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

    <span class="c1"># F1</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;TN&quot;</span><span class="p">:</span> <span class="n">TN</span><span class="p">,</span>
            <span class="s2">&quot;FP&quot;</span><span class="p">:</span> <span class="n">FP</span><span class="p">,</span>
            <span class="s2">&quot;FN&quot;</span><span class="p">:</span> <span class="n">FN</span><span class="p">,</span>
            <span class="s2">&quot;TP&quot;</span><span class="p">:</span> <span class="n">TP</span><span class="p">,</span>
            <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score_metric</span><span class="p">,</span>
            <span class="s2">&quot;Balanced Accuracy&quot;</span><span class="p">:</span> <span class="n">balanced_accuracy_score_metric</span><span class="p">,</span>
            <span class="s2">&quot;Prevalence&quot;</span><span class="p">:</span> <span class="n">prevalence</span><span class="p">,</span>
            <span class="s2">&quot;Sensitivity&quot;</span><span class="p">:</span> <span class="n">sensitivity</span><span class="p">,</span>
            <span class="s2">&quot;Specificity&quot;</span><span class="p">:</span> <span class="n">specificity</span><span class="p">,</span>
            <span class="s2">&quot;PPV&quot;</span><span class="p">:</span> <span class="n">PPV</span><span class="p">,</span>
            <span class="s2">&quot;NPV&quot;</span><span class="p">:</span> <span class="n">NPV</span><span class="p">,</span>
            <span class="s2">&quot;auc&quot;</span><span class="p">:</span> <span class="n">auc_score</span><span class="p">,</span>
            <span class="s2">&quot;Mean AUC (CI 5</span><span class="si">%-95%</span><span class="s2">)&quot;</span><span class="p">:</span> <span class="n">bootstrap_auc_metric</span><span class="p">,</span>
            <span class="s2">&quot;F1&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">df_metrics</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2022, James Twose.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>